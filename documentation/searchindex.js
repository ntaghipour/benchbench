Search.setIndex({"docnames": ["data", "index", "measures", "utils"], "filenames": ["data.rst", "index.rst", "measures.rst", "utils.rst"], "titles": ["Data", "Welcome to BenchBench\u2019s documentation!", "Measures", "Utils"], "terms": {"load_cardinal_benchmark": [0, 1], "dataset_nam": 0, "do_rerank": 0, "true": [0, 2, 3], "kwarg": 0, "sourc": [0, 2, 3], "load": 0, "cardin": [0, 1], "benchmark": [0, 1, 2], "paramet": [0, 2, 3], "str": [0, 3], "name": [0, 2], "bool": [0, 2, 3], "whether": [0, 2], "re": [0, 1], "rank": [0, 1, 2, 3], "base": [0, 1, 2], "averag": [0, 3], "score": [0, 2], "other": 0, "argument": 0, "return": [0, 2, 3], "pd": [0, 2], "datafram": [0, 1, 2], "list": [0, 1, 2, 3], "col": [0, 1, 2, 3], "type": [0, 2, 3], "tupl": [0, 2, 3], "load_ordinal_benchmark": [0, 1], "an": [0, 1, 3], "ordin": [0, 1], "win": [0, 2, 3], "rate": [0, 2, 3], "cardinal_benchmark_list": 0, "glue": [0, 1], "superglu": 0, "openllm": 0, "mmlu": 0, "bigbenchhard": 0, "mteb": 0, "vtab": 0, "ordinal_benchmark_list": 0, "bigcod": 0, "helm": [0, 1], "accuraci": [0, 1], "bia": 0, "calibr": 0, "fair": 0, "effici": 0, "robust": 0, "summar": 0, "toxic": 0, "heim": 0, "alignment_auto": 0, "nsfw": 0, "quality_auto": 0, "aesthetics_auto": 0, "alignment_human": 0, "nuditi": 0, "quality_human": 0, "aesthetics_human": 0, "black_out": 0, "origin": [0, 2], "i": [1, 2, 3], "python": 1, "packag": 1, "provid": 1, "suit": 1, "tool": 1, "evalu": 1, "multi": 1, "task": [1, 2], "focus": 1, "divers": [1, 2], "sensit": [1, 2], "irrelev": [1, 2], "chang": [1, 2, 3], "research": 1, "show": 1, "all": [1, 2, 3], "trade": 1, "off": 1, "between": [1, 2, 3], "The": [1, 2, 3], "more": 1, "its": 1, "ar": 1, "thing": 1, "like": 1, "introduc": 1, "weak": 1, "model": [1, 2, 3], "metric": 1, "wai": 1, "shouldn": 1, "t": 1, "matter": 1, "we": 1, "maintain": 1, "live": 1, "visit": 1, "project": 1, "page": 1, "see": 1, "contribut": 1, "your": 1, "own": 1, "pleas": 1, "relev": 1, "background": 1, "scientif": 1, "cite": 1, "inproceed": 1, "zhang2024inher": 1, "titl": 1, "inher": 1, "stabil": 1, "author": 1, "guanhua": 1, "zhang": 1, "moritz": 1, "hardt": 1, "booktitl": 1, "intern": 1, "confer": 1, "machin": 1, "learn": [1, 2], "year": 1, "2024": 1, "To": 1, "instal": 1, "simpli": 1, "run": 1, "pip": 1, "you": 1, "can": [1, 3], "us": [1, 2], "follow": 1, "code": [1, 3], "data": [1, 2, 3], "import": 1, "measur": 1, "get_divers": [1, 2], "get_sensit": [1, 2], "just": 1, "need": 1, "panda": 1, "column": [1, 2], "check": [1, 3], "detail": 1, "figur": 1, "colab": 1, "ipynb": 1, "banner": 1, "util": 1, "win_rat": 1, "index": 1, "modul": 1, "search": 1, "appr_rank_diff": 2, "old_rank": [2, 3], "use_weighted_loss": 2, "fals": [2, 3], "approxim": 2, "differ": [2, 3], "old": [2, 3], "new": [2, 3], "np": [2, 3], "arrai": [2, 3], "across": 2, "weight": 2, "loss": 2, "torch": 2, "tensor": 2, "calcul": [2, 3], "given": 2, "each": [2, 3], "row": 2, "repres": [2, 3], "w": [2, 3], "max_mrc": [2, 3], "where": [2, 3], "refer": 2, "max": [2, 3], "mrc": [2, 3], "over": [2, 3], "everi": [2, 3], "pair": [2, 3], "min_valu": 2, "0": 2, "01": 2, "lr": 2, "1": 2, "num_step": 2, "1000": 2, "stop_threshold": 2, "1e": 2, "05": 2, "normalize_epsilon": 2, "none": [2, 3], "return_weight": 2, "verbos": 2, "float": [2, 3], "min": 2, "valu": [2, 3], "epsilon": 2, "optim": 2, "int": [2, 3], "number": [2, 3], "step": 2, "stop": 2, "smaller": 2, "than": 2, "thi": 2, "normal": 2, "std": 2, "both": 2, "better": 2, "one": 2, "alpha": 2, "output": 2, "log": 2, "If": 2, "tau": [2, 3], "els": 2, "new_win_r": 2, "inv_indic": 2, "orig_rank": 2, "invaraint": 2, "indic": [2, 3], "onli": 2, "get_selected_win_r": 2, "win_rate_matrix": 2, "do_sampl": 2, "get": [2, 3], "select": [2, 3], "th": 2, "j": 2, "unnorm": 2, "probabl": 2, "l": 2, "sampl": 2, "new_indic": 2, "return_indic": 2, "rest": 2, "c": 2, "get_combin": 3, "": 3, "k": 3, "gener": 3, "subset": 3, "size": 3, "from": 3, "set": 3, "element": 3, "combin": 3, "A": 3, "is_int": 3, "x": 3, "string": 3, "convert": 3, "integ": 3, "input": 3, "otherwis": 3, "is_numb": 3, "rankdata": 3, "method": 3, "get_kendall_tau": 3, "new_rank": 3, "kendal": 3, "two": 3, "p": 3, "get_kendall_w": 3, "get_order_diff": 3, "new_ord": 3, "old_ord": 3, "legaci": 3, "order": 3, "get_order_vari": 3, "all_new_ord": 3, "varianc": 3, "get_rank_diff": 3, "get_rank_vari": 3, "all_new_rank": 3, "order2rank": 3, "rank2ord": 3, "class": 3, "winningr": 3, "object": 3, "get_winning_r": 3, "model_indic": 3}, "objects": {"benchbench": [[0, 0, 0, "-", "data"], [2, 0, 0, "-", "measures"], [3, 0, 0, "-", "utils"]], "benchbench.data": [[0, 1, 1, "", "cardinal_benchmark_list"], [0, 2, 1, "", "load_cardinal_benchmark"], [0, 2, 1, "", "load_ordinal_benchmark"], [0, 1, 1, "", "ordinal_benchmark_list"]], "benchbench.measures": [[2, 0, 0, "-", "cardinal"], [2, 0, 0, "-", "ordinal"]], "benchbench.measures.cardinal": [[2, 2, 1, "", "appr_rank_diff"], [2, 2, 1, "", "get_diversity"], [2, 2, 1, "", "get_sensitivity"]], "benchbench.measures.ordinal": [[2, 2, 1, "", "appr_rank_diff"], [2, 2, 1, "", "get_diversity"], [2, 2, 1, "", "get_selected_win_rate"], [2, 2, 1, "", "get_sensitivity"]], "benchbench.utils": [[3, 0, 0, "-", "base"], [3, 0, 0, "-", "metric"], [3, 0, 0, "-", "win_rate"]], "benchbench.utils.base": [[3, 2, 1, "", "get_combinations"], [3, 2, 1, "", "is_int"], [3, 2, 1, "", "is_number"], [3, 2, 1, "", "rankdata"]], "benchbench.utils.metric": [[3, 2, 1, "", "get_kendall_tau"], [3, 2, 1, "", "get_kendall_w"], [3, 2, 1, "", "get_order_diff"], [3, 2, 1, "", "get_order_variance"], [3, 2, 1, "", "get_rank_diff"], [3, 2, 1, "", "get_rank_variance"], [3, 2, 1, "", "order2rank"], [3, 2, 1, "", "rank2order"]], "benchbench.utils.win_rate": [[3, 3, 1, "", "WinningRate"]], "benchbench.utils.win_rate.WinningRate": [[3, 4, 1, "", "get_winning_rate"]]}, "objtypes": {"0": "py:module", "1": "py:attribute", "2": "py:function", "3": "py:class", "4": "py:method"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "attribute", "Python attribute"], "2": ["py", "function", "Python function"], "3": ["py", "class", "Python class"], "4": ["py", "method", "Python method"]}, "titleterms": {"data": 0, "benchbench": [0, 1, 2, 3], "welcom": 1, "": 1, "document": 1, "quick": 1, "start": 1, "exampl": 1, "usag": 1, "reproduc": 1, "result": 1, "from": 1, "our": 1, "paper": 1, "content": 1, "indic": 1, "tabl": 1, "measur": 2, "cardin": 2, "ordin": 2, "util": 3, "base": 3, "metric": 3, "win_rat": 3}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 58}, "alltitles": {"Data": [[0, "data"]], "benchbench.data": [[0, "module-benchbench.data"]], "Welcome to BenchBench\u2019s documentation!": [[1, "welcome-to-benchbench-s-documentation"]], "Quick Start": [[1, "quick-start"]], "Example Usage": [[1, "example-usage"]], "Reproduce the results from our paper": [[1, "reproduce-the-results-from-our-paper"]], "Contents:": [[1, null]], "Indices and tables": [[1, "indices-and-tables"]], "Measures": [[2, "module-benchbench.measures"]], "benchbench.measures.cardinal": [[2, "module-benchbench.measures.cardinal"]], "benchbench.measures.ordinal": [[2, "module-benchbench.measures.ordinal"]], "Utils": [[3, "module-benchbench.utils"]], "benchbench.utils.base": [[3, "module-benchbench.utils.base"]], "benchbench.utils.metric": [[3, "module-benchbench.utils.metric"]], "benchbench.utils.win_rate": [[3, "module-benchbench.utils.win_rate"]]}, "indexentries": {"benchbench.data": [[0, "module-benchbench.data"]], "cardinal_benchmark_list (benchbench.data attribute)": [[0, "benchbench.data.cardinal_benchmark_list"]], "load_cardinal_benchmark() (in module benchbench.data)": [[0, "benchbench.data.load_cardinal_benchmark"]], "load_ordinal_benchmark() (in module benchbench.data)": [[0, "benchbench.data.load_ordinal_benchmark"]], "module": [[0, "module-benchbench.data"], [2, "module-benchbench.measures"], [2, "module-benchbench.measures.cardinal"], [2, "module-benchbench.measures.ordinal"], [3, "module-benchbench.utils"], [3, "module-benchbench.utils.base"], [3, "module-benchbench.utils.metric"], [3, "module-benchbench.utils.win_rate"]], "ordinal_benchmark_list (benchbench.data attribute)": [[0, "benchbench.data.ordinal_benchmark_list"]], "appr_rank_diff() (in module benchbench.measures.cardinal)": [[2, "benchbench.measures.cardinal.appr_rank_diff"]], "appr_rank_diff() (in module benchbench.measures.ordinal)": [[2, "benchbench.measures.ordinal.appr_rank_diff"]], "benchbench.measures": [[2, "module-benchbench.measures"]], "benchbench.measures.cardinal": [[2, "module-benchbench.measures.cardinal"]], "benchbench.measures.ordinal": [[2, "module-benchbench.measures.ordinal"]], "get_diversity() (in module benchbench.measures.cardinal)": [[2, "benchbench.measures.cardinal.get_diversity"]], "get_diversity() (in module benchbench.measures.ordinal)": [[2, "benchbench.measures.ordinal.get_diversity"]], "get_selected_win_rate() (in module benchbench.measures.ordinal)": [[2, "benchbench.measures.ordinal.get_selected_win_rate"]], "get_sensitivity() (in module benchbench.measures.cardinal)": [[2, "benchbench.measures.cardinal.get_sensitivity"]], "get_sensitivity() (in module benchbench.measures.ordinal)": [[2, "benchbench.measures.ordinal.get_sensitivity"]], "winningrate (class in benchbench.utils.win_rate)": [[3, "benchbench.utils.win_rate.WinningRate"]], "benchbench.utils": [[3, "module-benchbench.utils"]], "benchbench.utils.base": [[3, "module-benchbench.utils.base"]], "benchbench.utils.metric": [[3, "module-benchbench.utils.metric"]], "benchbench.utils.win_rate": [[3, "module-benchbench.utils.win_rate"]], "get_combinations() (in module benchbench.utils.base)": [[3, "benchbench.utils.base.get_combinations"]], "get_kendall_tau() (in module benchbench.utils.metric)": [[3, "benchbench.utils.metric.get_kendall_tau"]], "get_kendall_w() (in module benchbench.utils.metric)": [[3, "benchbench.utils.metric.get_kendall_w"]], "get_order_diff() (in module benchbench.utils.metric)": [[3, "benchbench.utils.metric.get_order_diff"]], "get_order_variance() (in module benchbench.utils.metric)": [[3, "benchbench.utils.metric.get_order_variance"]], "get_rank_diff() (in module benchbench.utils.metric)": [[3, "benchbench.utils.metric.get_rank_diff"]], "get_rank_variance() (in module benchbench.utils.metric)": [[3, "benchbench.utils.metric.get_rank_variance"]], "get_winning_rate() (benchbench.utils.win_rate.winningrate method)": [[3, "benchbench.utils.win_rate.WinningRate.get_winning_rate"]], "is_int() (in module benchbench.utils.base)": [[3, "benchbench.utils.base.is_int"]], "is_number() (in module benchbench.utils.base)": [[3, "benchbench.utils.base.is_number"]], "order2rank() (in module benchbench.utils.metric)": [[3, "benchbench.utils.metric.order2rank"]], "rank2order() (in module benchbench.utils.metric)": [[3, "benchbench.utils.metric.rank2order"]], "rankdata() (in module benchbench.utils.base)": [[3, "benchbench.utils.base.rankdata"]]}})