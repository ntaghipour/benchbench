Model,Rank,Rank-Before,Average,Average-Before,BoolQ (× 0.0275),CB (× 0.0265),COPA (× 0.0226),MultiRC (× 0.0114),ReCoRD (× 1.0000),RTE (× 0.0201),WiC (× 0.0227),WSC (× 0.0181)
Turing NLR v5 ,1.0,3.0,13.715301277682707,90.9125,2.534537448430607,2.5645200067913967,2.2163474387506925,0.8599742037832465,96.15,1.890521147070905,1.7492231241197114,1.7572868525150918
ST-MoE-32B,2.0,2.0,13.54827385996474,91.16250000000001,2.545557176467262,2.5830746735072,2.238917168269539,0.8826947904089596,94.75,1.8784668145709844,1.7628357554358183,1.7446445010581486
ERNIE 3.0,3.0,4.0,13.501592124288752,90.61874999999999,2.50698812833897,2.62150934027565,2.1982916551356158,0.8622462624458179,94.45,1.860385315821103,1.756029439777765,1.7572868525150918
Vega v2,4.0,1.0,13.478634019273269,91.28125,2.4932134682931517,2.62150934027565,2.2434311141733083,0.8554300864581038,94.15,1.928693199987321,1.756029439777765,1.7807655052208433
DeBERTa / TuringNLRv4,5.0,7.0,13.474842943469204,90.28750000000001,2.490458536283988,2.5618693401177106,2.220861384654462,0.8628142771114606,94.3,1.872439648321024,1.7582982116637826,1.7320021496012057
T5 + UDG  Single Model (Google Brain),6.0,6.0,13.422860193693552,90.3875,2.518007856375625,2.563194673454553,2.211833492846923,0.8594061891176037,93.85,1.868421537487717,1.767373299207854,1.7446445010581486
PaLM 540B,7.0,5.0,13.410407435545046,90.425,2.5317825164214436,2.5234346733492603,2.2344032223657697,0.865086335774032,93.75,1.890521147070905,1.756029439777765,1.7320021496012057
T5,8.0,9.0,13.385828770483682,89.24999999999999,2.5124979923572974,2.5274106733597894,2.1396103583866157,0.8599742037832464,93.75,1.8583762604044498,1.7446855803476762,1.6940750952303762
Frozen T5 1.1 + SPoT,9.0,10.0,13.276463313980033,89.20624999999998,2.5097430603481334,2.563194673454553,2.1576661420016925,0.8508859691329612,92.85,1.8664124820710637,1.7197290896014803,1.6940750952303762
SuperGLUE Human Baselines,10.0,8.0,13.13128320522186,89.78750000000001,2.451889488155696,2.5804240068335136,2.2569729518846158,0.7594356079644653,91.5,1.8804758699876376,1.8150175088142273,1.8060502081347296
RoBERTa-mtl-adv,11.0,15.0,13.03813258402871,85.6875,2.3995457799815854,2.491626673265026,2.0583593321187696,0.7918124439061066,91.5,1.7699778220716975,1.6357845298188223,1.6579540910676818
RoBERTa (ensemble),12.0,14.0,13.01374143226207,85.875,2.4298500320823866,2.492952006601869,2.049331440311231,0.7827242092558215,91.25,1.7659597112383907,1.681159967539178,1.6579540910676818
RoBERTa,13.0,16.0,12.868545308653301,84.55,2.3995457799815854,2.4611440065176344,2.0448174944074617,0.777612077265036,90.3,1.7719868774883512,1.5858715483264312,1.6073846852399094
NEZHA-Plus,14.0,11.0,12.858014893181387,86.65000000000002,2.4188303040457315,2.5234346733492603,2.1125266829640004,0.7935164879030352,89.85,1.7900683762382321,1.692503826969267,1.683238793981568
RoBERTa-iCETS,15.0,13.0,12.810276447884862,85.94999999999999,2.4381148281098777,2.4969280066123987,2.0583593321187696,0.8213492065195341,89.6,1.8061408195714599,1.6539347049069648,1.6073846852399094
PAI Albert,16.0,12.0,12.69886375132657,86.0875,2.4270951000732226,2.502229339959771,2.071901169830077,0.791244429240464,88.65,1.7840412099882716,1.681159967539178,1.683238793981568
GPT-3 few-shot - OpenAI,17.0,25.0,12.634687975670259,71.7875,2.1047680550010694,1.6911253378117943,2.0764151157338464,0.6015275309157583,90.65,1.3862482374908869,1.1207733116927854,1.4466462167159184
ADAPET (ALBERT) - few-shot,18.0,21.0,12.142953553110651,76.05,2.2039456073309625,2.3100560061175215,1.927454900909462,0.6356084108543282,85.8,1.5067915624900943,1.2137929590195145,1.5459789781633284
iPET (ALBERT) - Few-Shot (32 Examples),19.0,22.0,12.113824655755637,75.425,2.2370047914409272,2.235837339254308,2.049331440311231,0.6009595162501155,85.65,1.422411234990649,1.1185045398067675,1.596548383991101
INSTALL(ALBERT)-few-shot,20.0,20.0,11.924987629933707,76.63125,2.1598666951843435,2.357768006243873,1.931968846813231,0.6304962788635426,83.9,1.504782507073441,1.3816820785848305,1.5333366267063855
AILabs Team  Transformers,21.0,17.0,11.730128907713445,82.6375,2.4270951000732226,2.470421339875536,1.9590525222358464,0.7940845025686781,81.3,1.7860502654049253,1.681159967539178,1.4231675640101669
Text to Text PETL,22.0,19.0,11.668231602330533,76.98750000000001,2.259044247514237,2.3763226729596765,1.8100923074114619,0.7111543613848247,81.75,1.5690722804063515,1.533689794948022,1.3364771540197
FSL++(ALBERT)-Few-Shot(32 Examples),23.0,18.0,11.651989328537828,77.66875,2.2342498594317632,2.382949339643892,1.9635664681396157,0.6571929681487557,81.5,1.5088006179067477,1.3726069910407594,1.596548383991101
BERT-mtl,24.0,24.0,10.70217560223609,73.48125,2.3361823437708202,2.4333120064439298,1.6656460384908462,0.589031208271616,74.3,1.689615605405559,1.5019269885437732,1.1016906269621851
BERT++,25.0,26.0,10.334730434764072,71.5125,2.1763962872393257,2.3219840061491093,1.6656460384908462,0.5345018003699041,71.65,1.5871537791562327,1.5790652326683776,1.1630963340387659
Bort (Alexa AI),26.0,23.0,7.64394114988689,74.10624999999999,2.30587809167002,2.2305360059069357,2.0222477648886157,0.7827242092558215,49.4,1.631352998322609,1.5904090920984666,1.188381036952652
select-step-by-step,27.0,27.0,2.8788726043800144,51.91875000000001,1.7135677096998236,1.9111306717277485,2.1757219256167697,0.002840073328214156,13.8,0.9985005420767693,1.2047178714754434,1.2245020411153467
WARP (ALBERT-XXL-V2) - Few-Shot (32 Examples),28.0,28.0,2.8058617056484847,48.75625,1.7135677096998236,2.0224586720225695,1.1645980431724618,0.002840073328214156,13.8,1.38825729290754,1.2047178714754434,1.1504539825818227
