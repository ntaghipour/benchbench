{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64eb7ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLUE 0.12, 0.73\n",
      "SuperGLUE 0.11, 0.30\n",
      "OpenLLM 0.46, 0.89\n",
      "MMLU 0.34, 0.93\n",
      "BigBenchHard 0.25, 0.80\n",
      "MTEB 0.18, 0.61\n",
      "VTAB 0.07, 0.27\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from benchbench.data import cardinal_benchmark_list\n",
    "from benchbench.data import load_cardinal_benchmark\n",
    "from benchbench.utils.base import rankdata\n",
    "from benchbench.measures.cardinal import get_sensitivity\n",
    "\n",
    "model_col_name = {\n",
    "    \"BigBenchHard\": \"Model\",\n",
    "    \"GLUE\": \"Model\",\n",
    "    \"MMLU\": \"model_name\",\n",
    "    \"MTEB\": \"Model\",\n",
    "    \"OpenLLM\": \"Model\",\n",
    "    \"SuperGLUE\": \"Model\",\n",
    "    \"VTAB\": None,\n",
    "}\n",
    "dir_out_before = \"./data/before\"\n",
    "dir_out_after = \"./data/after\"\n",
    "os.makedirs(dir_out_before, exist_ok=True)\n",
    "os.makedirs(dir_out_after, exist_ok=True)\n",
    "for bench in cardinal_benchmark_list:\n",
    "    data, cols = load_cardinal_benchmark(bench, do_rerank=False)\n",
    "    cols = list(cols)\n",
    "    data[\"Average\"] = data[cols].mean(axis=1)\n",
    "    data[\"Rank\"] = rankdata(-data[\"Average\"])\n",
    "    mc = model_col_name[bench]\n",
    "    if mc is None:\n",
    "        data[\"Model\"] = data.index\n",
    "    else:\n",
    "        data[\"Model\"] = data[mc]\n",
    "    data[\"Model\"] = data[\"Model\"].apply(lambda s: s.replace(\",\", \" \"))\n",
    "    data = data.sort_values(\"Rank\")\n",
    "    data = data.reset_index()\n",
    "    data[[\"Model\", \"Rank\", \"Average\"] + cols].to_csv(\n",
    "        f\"{dir_out_before}/{bench}.csv\", index=False\n",
    "    )\n",
    "\n",
    "    sensitivity, weights = get_sensitivity(data, cols, return_weight=True)\n",
    "    new_cols = [\"%s (Ã— %.4lf)\" % (c, w) for c, w in zip(cols, weights)]\n",
    "\n",
    "    weighted_df = data[cols].multiply(weights)\n",
    "    weighted_df.columns = new_cols\n",
    "    data = pd.concat([data, weighted_df], axis=1)\n",
    "\n",
    "    data[\"Rank-Before\"] = data[\"Rank\"]\n",
    "    data[\"Average-Before\"] = data[\"Average\"]\n",
    "    data[\"Average\"] = data[new_cols].mean(axis=1)\n",
    "    data[\"Rank\"] = rankdata(-data[\"Average\"])\n",
    "    data = data.sort_values(\"Rank\")\n",
    "    data = data.reset_index()\n",
    "    data[[\"Model\", \"Rank\", \"Rank-Before\", \"Average\", \"Average-Before\"] + new_cols].to_csv(\n",
    "        f\"{dir_out_after}/{bench}.csv\", index=False\n",
    "    )\n",
    "    print(bench, \"%.2lf, %.2lf\" % (sensitivity[0], sensitivity[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "current-roots",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 999, loss 1.92\n",
      "BigCode 0.04, 0.14\n",
      "Episode 999, loss 3.44\n",
      "HELM-accuracy 0.32, 0.67\n",
      "Episode 999, loss 4.67\n",
      "HELM-fairness 0.18, 0.58\n",
      "Episode 999, loss 3.70\n",
      "HELM-robustness 0.26, 0.58\n",
      "Episode 999, loss 0.60\n",
      "HEIM-alignment_auto 0.30, 0.50\n",
      "Episode 999, loss 1.00\n",
      "HEIM-quality_auto 0.10, 0.25\n",
      "Episode 999, loss 0.39\n",
      "HEIM-aesthetics_auto 0.40, 0.50\n",
      "Episode 999, loss 1.37\n",
      "HEIM-alignment_human 0.10, 0.25\n",
      "Episode 999, loss 0.26\n",
      "HEIM-nudity 0.39, 0.62\n",
      "Episode 999, loss 0.52\n",
      "HEIM-quality_human 0.10, 0.25\n",
      "Episode 999, loss 0.18\n",
      "HEIM-aesthetics_human 0.10, 0.25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from benchbench.data import load_ordinal_benchmark\n",
    "from benchbench.utils.base import rankdata\n",
    "from benchbench.utils.win_rate import WinningRate\n",
    "from benchbench.measures.ordinal import get_sensitivity\n",
    "\n",
    "\n",
    "ordinal_benchmark_list = [\n",
    "    \"BigCode\",\n",
    "    \"HELM-accuracy\",\n",
    "    \"HELM-fairness\",\n",
    "    \"HELM-robustness\",\n",
    "    \"HEIM-alignment_auto\",\n",
    "    \"HEIM-quality_auto\",\n",
    "    \"HEIM-aesthetics_auto\",\n",
    "    \"HEIM-alignment_human\",\n",
    "    \"HEIM-nudity\",\n",
    "    \"HEIM-quality_human\",\n",
    "    \"HEIM-aesthetics_human\",\n",
    "]\n",
    "\n",
    "model_col_name = {\n",
    "    \"BigCode\": \"Models\",\n",
    "    \"HELM-accuracy\": \"Model/adapter\",\n",
    "    \"HELM-fairness\": \"Model\",\n",
    "    \"HELM-robustness\": \"Model\",\n",
    "    \"HEIM-alignment_auto\": \"Model/adapter\",\n",
    "    \"HEIM-quality_auto\": \"Model/adapter\",\n",
    "    \"HEIM-aesthetics_auto\": \"Model/adapter\",\n",
    "    \"HEIM-alignment_human\": \"Model/adapter\",\n",
    "    \"HEIM-nudity\": \"Model/adapter\",\n",
    "    \"HEIM-quality_human\": \"Model/adapter\",\n",
    "    \"HEIM-aesthetics_human\": \"Model/adapter\",\n",
    "}\n",
    "\n",
    "dir_out_before = \"./data/before\"\n",
    "dir_out_after = \"./data/after\"\n",
    "os.makedirs(dir_out_before, exist_ok=True)\n",
    "os.makedirs(dir_out_after, exist_ok=True)\n",
    "for bench in ordinal_benchmark_list:\n",
    "    data, cols = load_ordinal_benchmark(bench, do_rerank=True)\n",
    "    cols = list(cols)\n",
    "    inv_indices = np.arange(len(data) // 5)\n",
    "    inv_data = data.iloc[inv_indices].copy()\n",
    "\n",
    "    win_rate_calculator = WinningRate(data, cols)\n",
    "    inv_data[\"WinRate\"] = win_rate_calculator.get_winning_rate(inv_indices)\n",
    "    inv_data[\"Rank\"] = rankdata(-inv_data[\"WinRate\"])\n",
    "    mc = model_col_name[bench]\n",
    "    inv_data[\"Model\"] = inv_data[mc]\n",
    "    inv_data[\"Model\"] = inv_data[\"Model\"].apply(lambda s: s.replace(\",\", \" \"))\n",
    "\n",
    "    sensitivity, new_indices = get_sensitivity(\n",
    "        data, cols, inv_indices=inv_indices, return_indices=True\n",
    "    )\n",
    "    new_data = data.iloc[new_indices].copy()\n",
    "\n",
    "    new_data[\"Model\"] = new_data[mc]\n",
    "    new_data[\"Model\"] = new_data[\"Model\"].apply(lambda s: s.replace(\",\", \" \"))\n",
    "    new_data[\"Rank-Before\"] = [\n",
    "        inv_data[\"Rank\"].values[i] if i in inv_indices else math.nan for i in new_indices\n",
    "    ]\n",
    "    new_data[\"WinRate-Before\"] = [\n",
    "        inv_data[\"WinRate\"].values[i] if i in inv_indices else math.nan for i in new_indices\n",
    "    ]\n",
    "    new_win_rate = win_rate_calculator.get_winning_rate(new_indices)[inv_indices]\n",
    "    new_data[\"WinRate\"] = [\n",
    "        new_win_rate[i] if i in inv_indices else math.nan for i in new_indices\n",
    "    ]\n",
    "    new_rank = rankdata(-new_win_rate)\n",
    "    new_data[\"Rank\"] = [new_rank[i] if i in inv_indices else math.nan for i in new_indices]\n",
    "\n",
    "    new_data = new_data.sort_values(\"Rank\")\n",
    "    new_data = new_data.reset_index()\n",
    "    new_data[\n",
    "        [\"Model\", \"Rank\", \"Rank-Before\", \"WinRate\", \"WinRate-Before\"] + cols\n",
    "    ].to_csv(f\"{dir_out_after}/{bench}.csv\", index=False)\n",
    "\n",
    "    inv_data = inv_data.sort_values(\"Rank\")\n",
    "    inv_data = inv_data.reset_index()\n",
    "    inv_data[[\"Model\", \"Rank\", \"WinRate\"] + cols].to_csv(\n",
    "        f\"{dir_out}/{bench}.csv\", index=False\n",
    "    )\n",
    "\n",
    "    print(bench, \"%.2lf, %.2lf\" % (sensitivity[0], sensitivity[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26aad185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ghzhang/Codes/benchmarking_aggregation_icml2023/benchmark\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03e5a890",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "236",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mjbl\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m cardinal_diversity \u001b[38;5;241m=\u001b[39m \u001b[43mjbl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/cardinal_diversity.jbl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m cardinal_sensitivity \u001b[38;5;241m=\u001b[39m jbl\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/cardinal_sensitivity.jbl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m ordinal_diversity \u001b[38;5;241m=\u001b[39m jbl\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/ordinal_diversity.jbl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/py38_tf/lib/python3.8/site-packages/joblib/numpy_pickle.py:585\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    580\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    581\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    582\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[0;32m--> 585\u001b[0m             obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/miniforge3/envs/py38_tf/lib/python3.8/site-packages/joblib/numpy_pickle.py:504\u001b[0m, in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    502\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 504\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[1;32m    506\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    507\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    509\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[1;32m    510\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/py38_tf/lib/python3.8/pickle.py:1212\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1212\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "\u001b[0;31mKeyError\u001b[0m: 236"
     ]
    }
   ],
   "source": [
    "import joblib as jbl\n",
    "\n",
    "cardinal_diversity = jbl.load(\"./data/cardinal_diversity.jbl\")\n",
    "cardinal_sensitivity = jbl.load(\"./data/cardinal_sensitivity.jbl\")\n",
    "ordinal_diversity = jbl.load(\"./data/ordinal_diversity.jbl\")\n",
    "ordinal_sensitivity = jbl.load(\"./data/ordinal_sensitivity.jbl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
